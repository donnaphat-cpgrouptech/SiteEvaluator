{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and Save Transportation/Business Sat DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess_map_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess_map_data.py\n",
    "import os\n",
    "import pickle\n",
    "from pyrosm import OSM, get_data\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--score_type\", help=\"Input type of score would like to preprocess/update ['business' or 'transporation']\",type=str)\n",
    "parser.add_argument(\"--update_pbf\", help=\"Update map information file (Protobuf)\",type=bool)\n",
    "args = parser.parse_args()\n",
    "score_type = args.score_type\n",
    "if args.score_type not in ['business', 'transporation']:\n",
    "    raise Exception(\"Undefine score type\")\n",
    "\n",
    "LOAD_FILE = './data/{}_filter_dict.pickle'.format(score_type)\n",
    "SAVE_FILE = './data/{}-latest.csv'.format(score_type)\n",
    "\n",
    "if os.path.isfile('./data/Bangkok.osm.pbf'):\n",
    "    if args.update_pbf:\n",
    "        fp = get_data(\"bangkok\", directory=\"/data\", update=True)\n",
    "    else:\n",
    "        fp = './data/Bangkok.osm.pbf'\n",
    "else:\n",
    "    fp = get_data(\"bangkok\", directory=\"/data\", update=True)\n",
    "osm = OSM(fp)\n",
    "\n",
    "\n",
    "with open(LOAD_FILE, 'rb') as f:\n",
    "    my_filter, combine_dict = pickle.load(f)\n",
    "    print('Finish load infos from: {}'.format(LOAD_FILE))\n",
    "\n",
    "filter_key = list(my_filter.keys())\n",
    "pois = osm.get_pois(custom_filter=my_filter)\n",
    "merged_filter_col = pois[filter_key[0]].fillna('')\n",
    "merged_filter_col = pois[filter_key[0]].fillna('')\n",
    "[merged_filter_col := merged_filter_col+pois[filter_key[i]].fillna('') for i in range(1, len(filter_key))]\n",
    "pois['poi_type'] = merged_filter_col\n",
    "pois.to_csv(SAVE_FILE)\n",
    "print('Finish save preprocess data to: {}'.format(SAVE_FILE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "from AreaMap import AreaMap, boundingBox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_or_combine_tag(df, keyword, replace_word):\n",
    "  filter = np.where(df['poi_type'].str.contains(keyword, case=False, na=False), True, False)\n",
    "  df.loc[filter, 'poi_type']=replace_word\n",
    "\n",
    "def compute_score(categoried_df):\n",
    "    # Concat each point's dataframe to main dataframe\n",
    "    df = pd.concat(categoried_df, axis=1).fillna(0)\n",
    "    # prepare list for keep sum of rank score for each point\n",
    "    # if we have 4 interested point max rank score = 4, min rank score = 1\n",
    "    sum_rank = [0 for i in range(len(categoried_df))]\n",
    "\n",
    "    \n",
    "    description = {'Point {}'.format(i):[] for i in range(len(categoried_df))}\n",
    "    desc_key = list(description.keys())\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        row = [row[key] for key in desc_key]\n",
    "        rank = rankdata(row, method='max')\n",
    "        for i in range(len(desc_key)):\n",
    "            description[desc_key[i]].append('This location have {} score rank: {}'.format(index, (4-rank[i])+1))\n",
    "        sum_rank+=rank\n",
    "    \n",
    "    # Compute score (Max score=100)\n",
    "    score = (sum_rank/len(df.index))*(100/len(categoried_df))\n",
    "\n",
    "    # last row is a overall score\n",
    "    df.loc[len(df)] = score\n",
    "    # get the all index and set last index to \"Overall score\".\n",
    "    as_list = df.index.tolist()\n",
    "    idx = as_list.index(len(df)-1)\n",
    "    as_list[idx] = 'Overall score'\n",
    "    df.index = as_list\n",
    "    return df, pd.DataFrame(description, index=as_list[:-1])\n",
    "\n",
    "\n",
    "def return_format(clean_result, score_df, rank_df):\n",
    "    score_json = json.loads(score_df.to_json())\n",
    "    rank_json = json.loads(rank_df.to_json())\n",
    "\n",
    "    ret = {}\n",
    "    for i in range(len(clean_result)):\n",
    "        key = 'Point {}'.format(i)\n",
    "        \n",
    "        ret[key] = {\n",
    "            'score' : score_json[key],\n",
    "            'rank': rank_json[key],\n",
    "            'properties': [item['properties'] for item in json.loads(clean_result[i].to_json())['features']] #Extract only real data, ignore auto-generate from pandas\n",
    "        }\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 2084.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Transportation score = True, Business Saturation score = False\n",
    "score = True\n",
    "\n",
    "interested_points = [\n",
    "    {\n",
    "      'lat': 13.757929379398433,\n",
    "      'long': 100.5655348237836\n",
    "    },\n",
    "    {\n",
    "      'lat': 13.7649760109863,\n",
    "      'long': 100.53827980930785\n",
    "    },\n",
    "    {\n",
    "      'lat': 13.72193753690904,\n",
    "      'long': 100.53024243361882\n",
    "    },\n",
    "    {\n",
    "      'lat':13.711183848783898, \n",
    "      'long':100.48792930114243\n",
    "    }\n",
    "]\n",
    "# if score:\n",
    "#     my_filter={\n",
    "#       \"amenity\":[\"bicycle_parking\", \"bus_station\", \"ferry_terminal\", \"fuel\", \"charging_station\", \"motorcycle_parking\", \"parking\", \"parking_space\", \"taxi\"], \n",
    "#       \"highway\":[\"platform\", \"primary\", \"secondary\"],\n",
    "#       \"railway\":[\"construction\", 'station']\n",
    "#     }\n",
    "\n",
    "#     combine_dict = {\n",
    "#       'bus': 'Bus stop',\n",
    "#       'parking': 'Parking space',\n",
    "#       'primary': 'Primary road',\n",
    "#       'secondary': 'Secondary road',\n",
    "#       'station': 'BTS/MRT/SRT',\n",
    "#       'construction': 'BTS/MRT/SRT (Under construction)',\n",
    "#       'fuel': 'Gas station'\n",
    "#     }\n",
    "# else:\n",
    "#     business_filter = {\n",
    "#         \"education\": [\n",
    "#             \"college\", \"driving_school\", \"kindergarten\", \n",
    "#             \"Language_school\", \"library\", \"toy_library\", \n",
    "#             \"training\", \"music_school\", \"school\", \n",
    "#             \"traffic_park\", \"university\"\n",
    "#         ],\n",
    "#         \"finance\": [\n",
    "#             \"atm\", \"bank\", \"bureau_de_change\"\n",
    "#         ],\n",
    "#         \"healthcare\": [\n",
    "#             \"baby_hatch\", \"clinic\", \"dentist\",\n",
    "#             \"hosipital\", \"nursing_home\", \"pahrmacy\",\n",
    "#             \"social_facility\", \"veterinary\"\n",
    "#         ],\n",
    "#         \"entertainment-art-cultural\": [\n",
    "#             \"arts_centre\", \"casino\", \"cinema\", \"monastery\"\n",
    "#             \"community_centre\", \"conference_centre\", \"events_venue\", \n",
    "#             \"exhibition_centre\", \"fountain\", \"gambling\", \"music_venue\"\n",
    "#             \"nightclub\", \"planetarium\", \"public_bookcase\",\n",
    "#             \"social_centre\", \"studio\", \"theatre\", \"internet_cafe\"\n",
    "#         ],\n",
    "#         \"facilities\": [\n",
    "#             \"marketplace\", \"mailroom\", \"townhall\", \n",
    "#             \"post_office\", \"post_depot\", \"post_box\", \"police\"]\n",
    "#     }\n",
    "\n",
    "#     my_filter = {\n",
    "#         \"amenity\": [val for k, v in business_filter.items() for val in v]\n",
    "#     }\n",
    "\n",
    "#     combine_dict = {val:k for k, v in business_filter.items() for val in v }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_type = 'business'\n",
    "with open('{}_filter_dict.pickle'.format(score_type), 'rb') as f:\n",
    "    my_filter, combine_dict = pickle.load(f)\n",
    "    \n",
    "bangkok_df = pd.read_csv('{}-latest.csv'.format(score_type))\n",
    "\n",
    "bangkok_df['geometry'] = bangkok_df['geometry'].apply(wkt.loads)\n",
    "bangkok_gdf = geopandas.GeoDataFrame(bangkok_df, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for point in interested_points:\n",
    "    bottom, left, top, right = list(boundingBox(point['lat'], point['long'], 1))\n",
    "    AreaPolygon = Polygon(((left, top), (right, top), (right, bottom), (left, bottom)))\n",
    "    tmp = bangkok_gdf[bangkok_gdf['geometry'].covered_by(AreaPolygon)].reset_index(drop=True)\n",
    "    tmp = tmp.loc[:, ~tmp.columns.str.contains('^Unnamed')]\n",
    "    result.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result)):\n",
    "  for key, val in combine_dict.items():\n",
    "    replace_or_combine_tag(result[i], key, val)\n",
    "\n",
    "clean_result = [\n",
    "    result[i]\n",
    "      .dropna(how='all', subset=['name', 'tags', 'operator'])\n",
    "      .drop_duplicates(subset=['name', 'poi_type'])\n",
    "    for i in range(len(result))\n",
    "]\n",
    "\n",
    "categoried_result = [\n",
    "    clean_result[i]\n",
    "      .groupby('poi_type', group_keys=True)\n",
    "      .apply(lambda x: int(len(x)))\n",
    "      .to_frame(name=\"Point {}\".format(i)) \n",
    "    for i in range(len(clean_result))\n",
    "]\n",
    "\n",
    "score_df, rank_df = compute_score(categoried_result)\n",
    "ret = return_format(clean_result, score_df, rank_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "site_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aff15f304754b366e05cd1555f4b758654a028dfaece3d9674cfedf10299476b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
